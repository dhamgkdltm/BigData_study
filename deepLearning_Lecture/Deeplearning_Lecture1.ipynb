{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZZOB5pAh9TBK"
      },
      "outputs": [],
      "source": [
        "import torch # torch는 딥러닝을 구성하기 편하도록 페이스북에서 만든 딥러닝 라이브러리, 텐서플로우와 같은 딥러닝 라이브러리이다\n",
        "import torch.nn as nn  # 신경망 구축을 쉽게 해주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인 , gpu가 없으면 cpu로 연산, gpu가 있으면 gpu로 연산하겠다는 준비, 따라서 device는 cpu나 gpu 문자열로 바뀐다.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CknplUv9AIzj",
        "outputId": "b6365d8b-2d08-48b8-9b41-1889741b1cfe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4명의 데이터가 있는데, 1명당 2개의 컬럼을 가지고 있다. 그리고 그걸 2차원 리스트로 4명의 데이터를 선언 후\n",
        "# 토치가 이해할 수 있는 텐서타입으로 바꾼다.\n",
        "# 이때, 텐서타입은 float\n",
        "# to(device)는 모델이 gpu에서 연산될 것이기 때문에 to(cuda)를 함으로써 데이터를 gpu에 얹어 놓는다.\n",
        " \n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "metadata": {
        "id": "B8T-EPbnAJWc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2,10, bias=True,), # input_layer = 2, hidden_layer1 = 10\n",
        "    nn.Sigmoid(),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,10, bias=True,), # hidden_layer1 = 10, hidden_layer2 = 10\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,10, bias=True,), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,1, bias=True,), # hidden_layer3 = 10, output_layer = 1\n",
        "    nn.Sigmoid(),\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "7VrYgMosAMki"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss().to(device) # Mean Square Error\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001) # 옵티마이저인 Stochastic Gradient Descent를 사용.\n",
        "                                                           # 업데이트 대상은 model 객체가 가지고 있는 w들을 대상으로 업데이트를 할 것이고, learning rate는 0.001로 설정할 것이다."
      ],
      "metadata": {
        "id": "P1XIfV6BAdSJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50): # 50번의 학습\n",
        "  optimizer.zero_grad() # 옵티마이저의 기울기를 매번 초기화해서 계산해야하기 때문에 초기화 하는 함수를 선언\n",
        "  # forward 연산\n",
        "  hypothesis = model(X) # 모델에 데이터를 넣고, propagation을 진행한 후, 최종 아웃풋을 hypothesis에 담는다.\n",
        "\n",
        "  # 비용 함수\n",
        "  cost = criterion(hypothesis, Y) # 예측값과 정답값 사이의 Mean Square Loss를 구함\n",
        "  cost.backward() # backpropagation이 아니다. 이 부분은 기울기를 구하는 함수\n",
        "  optimizer.step() # 여기서 비로소 backpropagation을 실행해 모델이 모든 w들을 업데이트 한다.\n",
        "\n",
        "  # 5의 배수에 해당되는 에포크마다 비용을 출력\n",
        "  if epoch % 5 == 0 :\n",
        "    print(\"에폭:\", epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwIc6LuHEehx",
        "outputId": "929b5494-4d5e-4697-cd6b-effc086039ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에폭: 0 0.25263649225234985\n",
            "에폭: 5 0.25166529417037964\n",
            "에폭: 10 0.25093400478363037\n",
            "에폭: 15 0.2504405379295349\n",
            "에폭: 20 0.2501578629016876\n",
            "에폭: 25 0.25003504753112793\n",
            "에폭: 30 0.25000813603401184\n",
            "에폭: 35 0.2500186264514923\n",
            "에폭: 40 0.2500295341014862\n",
            "에폭: 45 0.2500287890434265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_2 = torch.FloatTensor([[0,0], [0,1]]).to(device)\n",
        "hypothesis = model(X_2) # fitting된 모델에 데이터를 넣어서 inference하는 부분\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywrWYPF5FVlz",
        "outputId": "0a63721e-cc56-4f72-9dcd-3769ca05f49e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4963],\n",
            "        [0.4959]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "# minibatch DNN\n",
        "#\n",
        "#"
      ],
      "metadata": {
        "id": "nzqccrvUGQYj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "metadata": {
        "id": "IuVAaBpAHyWp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "S7fG3l9RH_TM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "# 정답값은 1사람당 1개\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "BzUOguZ4IGpa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X 데이터셋과 Y 데이터 셋을 포장함.\n",
        "dataset = TensorDataset(x_train, y_train)\n",
        "print(list(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX-gPWx_Ilnr",
        "outputId": "381f5be9-d844-416f-c84b-1eb11ccc9534"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor([73., 80., 75.]), tensor([152.])), (tensor([93., 88., 93.]), tensor([185.])), (tensor([89., 91., 90.]), tensor([180.])), (tensor([ 96.,  98., 100.]), tensor([196.])), (tensor([73., 66., 70.]), tensor([142.]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2개 데이터를 1세트로 만들어서 전체데이터셋을 나눈다. 이때, n개의 세트들의 순서를 shuffle한다.\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "zAn48roJIp2O"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(3, 10, bias=True), # input_layer = 3, hidden_layer1=10\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2=10\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3=10\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer=1\n",
        "    nn.ReLU()\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "ouRnzj9sIxEL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) # 0.00001"
      ],
      "metadata": {
        "id": "ETb1kUylKgDN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# minibatch로 실행할 경우 backpropagation이 더 빈번하게 일어난다.\n",
        "nb_epochs = 5\n",
        "for epoch in range(nb_epochs + 1): # 전체 데이터 셋으로 5번 학습할 것이다.\n",
        "  for batch_idx, samples in enumerate(dataloader): # minibatch 데이터를 반환하면서 index도 반환한다. GPU폭발 방지를 위해 minibatch로 실행\n",
        "    \n",
        "    x_train, y_train = samples\n",
        "\n",
        "    x_train = x_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = criterion(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4}/{} Batch {}/{} Cost: {:6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnBROg6iKw_3",
        "outputId": "326edd11-ae89-4966-a5e6-d0eb77526450"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/5 Batch 1/3 Cost: 196.565613\n",
            "Epoch    0/5 Batch 2/3 Cost: 67.147804\n",
            "Epoch    0/5 Batch 3/3 Cost: 147.798904\n",
            "Epoch    1/5 Batch 1/3 Cost: 286.899658\n",
            "Epoch    1/5 Batch 2/3 Cost: 480.501282\n",
            "Epoch    1/5 Batch 3/3 Cost: 834.715820\n",
            "Epoch    2/5 Batch 1/3 Cost: 1068.082764\n",
            "Epoch    2/5 Batch 2/3 Cost: 945.053589\n",
            "Epoch    2/5 Batch 3/3 Cost: 1670.123291\n",
            "Epoch    3/5 Batch 1/3 Cost: 18.280916\n",
            "Epoch    3/5 Batch 2/3 Cost: 23.409044\n",
            "Epoch    3/5 Batch 3/3 Cost: 67.413734\n",
            "Epoch    4/5 Batch 1/3 Cost: 68.401115\n",
            "Epoch    4/5 Batch 2/3 Cost: 65.779694\n",
            "Epoch    4/5 Batch 3/3 Cost: 116.002853\n",
            "Epoch    5/5 Batch 1/3 Cost: 320.265900\n",
            "Epoch    5/5 Batch 2/3 Cost: 619.203003\n",
            "Epoch    5/5 Batch 3/3 Cost: 143.769745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#"
      ],
      "metadata": {
        "id": "UgNLMpvkLwUM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ozOOKXU-W1gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-9-s-BVMSY-d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbfI6-pRSiMI",
        "outputId": "57772c22-8ec0-4693-8cdf-177ae0e9a9c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f26581c7590>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001 # 옵티마이저의 learning rate\n",
        "training_epochs = 15 # 학습 횟수\n",
        "batch_size = 100 # minibatch 사이즈, 전체 데이터셋에서 서브 셋을 몇개로 묶을거냐"
      ],
      "metadata": {
        "id": "tbEJBqWsS2il"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=False,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCVmhcLITDP7",
        "outputId": "d09a86a9-5946-40d1-9ed6-e36ba4308cdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 113368412.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 18862611.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 23302384.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7891685.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True,\n",
        "                                         drop_last=True) # drop_last 마지막 남은 데이터를 버릴지 선택"
      ],
      "metadata": {
        "id": "6TslRKXvTbD8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.Module:  PyTorch의 모든 Neural Network의 Base Class\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        # ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        # ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "NiUQ7i_jW5kN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "xsi2vbzJivyH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "gK9i1ifSiwp4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(data_loader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIDafR_2ixiC",
        "outputId": "4b719d93-26dc-4d0b-ecea-01b1fa87007d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 배치의 수 : 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
        "        # image is already size of (28x28), no reshape\n",
        "\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX7x_yNwiynh",
        "outputId": "10874c99-29e1-43f9-d422-ef0412d3df8f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.225602373\n",
            "[Epoch:    2] cost = 0.0631315187\n",
            "[Epoch:    3] cost = 0.0463035554\n",
            "[Epoch:    4] cost = 0.0374769792\n",
            "[Epoch:    5] cost = 0.0313607678\n",
            "[Epoch:    6] cost = 0.0262179915\n",
            "[Epoch:    7] cost = 0.0219778605\n",
            "[Epoch:    8] cost = 0.0184681527\n",
            "[Epoch:    9] cost = 0.0161481686\n",
            "[Epoch:   10] cost = 0.0131634325\n",
            "[Epoch:   11] cost = 0.00995935686\n",
            "[Epoch:   12] cost = 0.0101486538\n",
            "[Epoch:   13] cost = 0.00830312911\n",
            "[Epoch:   14] cost = 0.00703515206\n",
            "[Epoch:   15] cost = 0.00613190467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "                        # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다\n",
        "                        # 이를 axis 1방향으로 max값을 찾는다는 것\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "                          # torch.argmax(prediction, 1)은 피쳐값중 max인 인덱스를 반환\n",
        "    \n",
        "    print( f1_score(torch.argmax(prediction, 1), Y_test) )\n",
        "\n",
        "    # accuracy = correct_prediction.float().mean()\n",
        "    # print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "id": "y6YDfuIuX2UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "torch.save(model.state_dict(), \"cnn_model.pt\")"
      ],
      "metadata": {
        "id": "MZmSazUuaJQ1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다시 불러와서 추론해보기\n",
        "model = CNN().to(device)\n",
        "model.load_state_dict(torch.load(\"cnn_model.pt\"))\n",
        "model.eval() # 평가 모드로 설정하여야 합니다. 이 과정을 거치지 않으면 일관성 없는 추론 결과가 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGLt-EOXaS71",
        "outputId": "6841c8a6-d32d-47f2-d26a-6608cd280151"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3x5pnwRsZRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    # 이미지 파일 경로 설정\n",
        "    img = Image.open(\"./8.png\")\n",
        "    transform = transforms.Compose([\n",
        "          transforms.Grayscale(num_output_channels=1), # RGB(3D) -> Gray(2D)\n",
        "          transforms.Resize((28, 28)), # 모델 인풋에 맞게\n",
        "          transforms.ToTensor(), # 토치 텐서 타입으로 맞춰줘야함\n",
        "      ])\n",
        "    \n",
        "    img_tensor = transform(img).to(device) # [1, 28, 28]\n",
        "    img_tensor = img_tensor.unsqueeze(0) # [1, 1, 28, 28] # 모델이 원래의 [배치사이즈, 채널, 가로, 세로]\n",
        "\n",
        "    print(img_tensor.shape)\n",
        "\n",
        "    prediction = model(img_tensor)\n",
        "                        # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것 \n",
        "    print('result:', torch.argmax(prediction, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k962fv8ItZ_d",
        "outputId": "3054948d-005d-417f-dc0c-763811dc4d81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "result: tensor([5], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9Bl7zThtc_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}